# Neural Network Configuration

# Model Architecture
model:
  type: "Network"
  layers:
    - name: "input layer"
      input_size: 784
      output_size: 1
      kernel:
        type: "DENKernel"
        n: 784
        tau_s: 15
        tau_m: 3.75
        learning: False
      
      learning_rule:
        type: "SingleSpikeLR"
        threshold: 0.5

# Optimizer
optimizer:
  type: "Momentum"
  learning_rate: 1.0
  mu: 0.99

# Loss Function
loss:
  type: "BinaryLoss"

# Training Parameters
training:
  epochs: 20
  batch_size: 32
  validation_split: 0.2  # 20% of the training data used for validation
  shuffle: True

# Dataset
dataset:
  name: "RandomDataset"
  path: "./outputs/data/random"  # Path to the dataset
  normalize: False  # Normalize values to [0, 1]
  flatten: True

  encoder:
    name: "LatencyEncoder"
    max_value: 1.0

# Callbacks (Optional)
callbacks:
  - type: "EarlyStopping"
    monitor: "val_loss"
    patience: 3
    restore_best_weights: True
  - type: "ModelCheckpoint"
    filepath: ".outputs/checkpoints/model_{epoch}.pkl"
    save_best_only: True
  - type: "MLFlowLogger"
    log_dir: "./logs"
    histogram_freq: 1